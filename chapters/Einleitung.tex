\documentclass[../Bachelor_LennartKoliwer.tex]{subfiles}
\graphicspath{{\subfix{../images/}}}
\begin{document}


Dynamic Mode Decomposition, kurz DMD, ist ein datengetriebener Algorithmus, der ursprünglich im Feld der Strömungsdynamik entwickelt wurde. 
Grundsätzlich dient er zur Analyse dynamischer Systeme mittels Sigulärwertzerlegung großer Datenmatrizen.
DMD kann anhand von Messdaten mehrerer Zeitpunkte die Dynamik eines Systems approximieren. Die Genauigkeit hängt unter anderem davon ab, wie viele Informationen in Form von Messdaten man über das System hat und wie groß die Messfehler also das Rauschen der Daten ist.
Dabei ist DMD gut im Erkennen von Mustern, wie im Falle der Strömungsdynamik z.B. Verwirbelungen. 

\textcolor{red}{in der einleitung doch kein exact dmd muss noch umschreiben..}

Ein Problem das beim klassischen DMD auftaucht, ist das die Zeitabstände zwischen den Messdaten einheitlich sein müssen, was spätestens, wenn man DMD außerhalb von Simulationen anwenden will, zu Problemen führen wird.
Im Laufe der letzten Jahre wurden eine Vielzahl von Varianten der DMD Algorithmen entwickelt, um zum Beispiel unterschiedliche Schwächen des Algorithmus auszugleichen.
Wir betrachten hier zur Vereinfachung den exact DMD Algorithmus.
Diese Variante hat den Vorteil gegenüber des ursprünglichen DMD, dass die Messzeitpunkte keine einheitlichen Zeitabstände benötigen.
Für jede Messung werden alle Daten in eine Spalte $x_i$ einer Datenmatrix $X$ eingetragen. 
Zusätzlich legen wir eine zweite Datenmatrix $X'$ so an, dass wir in $X$ die Messungen $(x_1,\dots,x_{k-1})$ und in $X'$ die Messungen $(x_2,\dots,x_k)$ haben.
Das Ziel von DMD ist es nun einen linearen Operator $A$ zu finden, welcher das optimale Ergebnis von $$A=\underset{A}{\arg\min}\dabs{X'-AX}_F\,,$$ der das System $X' \approx AX$ so gut wie möglich beschreibt. Hier ist $\dabs{\cdot}_F$ die Frobeniusnorm, welche wir später noch genauer beschreiben werden.
Diesen Operator bestimmt man mittels Singulärwertzerlegung unserer Datenmatrix $X$. 
Die Singulärwertzerlegung (SVD) beschreiben wir auch später nochmal genauer, liefern aber für einen kleinen Überblick eine vereinfachte Beschreibung.
Bei der SVD finden wir für ein $X\in\RR^{n\times m}$ zwei orthogonale Matrizen $U$ und $V$ mit passenden Dimensionen und ${\hat{\Sigma}=\diag(\sigma_1,\dots,\sigma_r)}$ mit $r\leq\min(n,m)$ und $\sigma_1 \geq \sigma_2 \geq \dots \geq \sigma_r > 0$ so, dass
\[
	X = U\Sigma V^\top \text{ mit } \Sigma = \begin{pmatrix}
		\hat{\Sigma} & 0 \\
		0            & 0
	\end{pmatrix} \in \mathbb{R}^{n\times m}
\]
gilt. \textcolor{red}{(}Damit können wir die SVD mit $u_i$ und $v_i$ als linke und rechte Singulärvektoren auch durch $X=\sum_{i=1}^{r}\sigma_iu_iv^\top_i$ beschreiben.\textcolor{red}{) hab ich erstmal eingeführt, um einfacher auf die Notation vom Paper zu verweisen (das ist ja aber noch wip)}

Um für die folgenden Schritte der DMD den Rechenaufwand zu minimieren, lohnt es sich eine Dimensionsreduktion durchzuführen. Eine Möglichkeit ist als ökonomischer SVD (TSVD) bekannt.
Dabei wird $\Sigma$ auf eine $r\times r$ große Matrix reduziert und die Spalten von $U$ und $V$ abgeschnitten, sodass wir mit den reduzierten Matrizen $U_r$, $\Sigma_r$ und $V_r$, 
\[
X_r=U_r\Sigma_rV_r^\top=U_r\hat{\Sigma}V_r^\top
\] 
erhalten.
Mit der Frobeniusnorm
\begin{align*}
    \dabs{X_r}_F^2=\sum_{i=1}^{r}\sigma_i^2
\end{align*}
lässt sich dann zeigen, dass $X_r$ nach dem Eckart-Young-Mirsky-Theorem die beste Rang$\,r$-Approximation bezüglich der Frobeniusnorm ist.

In der Realität tauchen beim Messen aber Fehler auf. Das heißt, unsere Singulärwerte sind zu einem Teil echt, aber auch zu einem Teil Messfehler.
Wir definieren die Datenmatrix also durch 
\[
    X \coloneqq \Xtrue+\gamma \Xnoise
\]
einen echten Teil und einem durch $\gamma$ skalierten Fehleranteil.


\textcolor{red}{Grobe Richtung} Im Paper \cite{OHT} von Matan Gavish und David L. Donoho erhalten wir durch \textcolor{red}{...}, dass quadratische $n\times n$ Matrizen ab einem Singulärwert von $\tau=\frac{4}{\sqrt{3}}\gamma\sqrt{n}$ abgeschnitten werden. \textcolor{red}{...}


\textcolor{red}{Gavish Donoho weiter ausführen}


\textcolor{red}{Überleitung zu MP}
Bei kleinen Matrizen ist das Rauschen kaum ein Problem aber für \glqq große\grqq\ Matrizen kann der Noiseanteil der Singulärwerte sehr groß werden. 



\end{document}